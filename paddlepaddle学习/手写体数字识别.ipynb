{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python高级程序设计\\.venv\\lib\\site-packages\\matplotlib_inline\\config.py:66: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "#加载飞桨和相关类库\n",
    "import paddle\n",
    "from paddle.nn import Linear\n",
    "import paddle.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置数据格式\n",
    "paddle.vision.set_image_backend('cv2')\n",
    "train_dataset = paddle.vision.MNIST(mode='train')\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0][0],cmap='binary')\n",
    "plt.axis('off')\n",
    "print(train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型设计，定义假设空间\n",
    "class  MINIST(paddle.nn.Layer):\n",
    "    def __init__(self) -> None:\n",
    "        super(MINIST,self).__init__()\n",
    "\n",
    "        self.fc = paddle.nn.Linear(in_features=784,out_features=1)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        predict  =  self.fc(inputs)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化处理\n",
    "def norm_img(img):\n",
    "    assert len(img.shape) == 3\n",
    "\n",
    "    img = img/225\n",
    "\n",
    "    img  = paddle.reshape(img,[-1,784])\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = paddle.io.DataLoader(\n",
    "    train_dataset,#数据源\n",
    "    batch_size = 16,# 每次训练的样本大小\n",
    "    shuffle = True #样本顺序打乱\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练过程\n",
    "model = MINIST()\n",
    "\n",
    "iter_num = 0\n",
    "all_iter = []\n",
    "all_loss = []\n",
    "def train(model):\n",
    "    model.train()\n",
    "\n",
    "    #定义优化器\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.001,parameters=model.parameters())\n",
    "\n",
    "    # 定义输入\n",
    "    data_loader = paddle.io.DataLoader(\n",
    "        train_dataset,#数据源\n",
    "        batch_size = 16,# 每次训练的样本大小\n",
    "        shuffle = True #样本顺序打乱\n",
    "    )\n",
    "\n",
    "    epoch_num = 10\n",
    "    for i in range(epoch_num):\n",
    "        for batch_id,data in enumerate(data_loader):\n",
    "            img = norm_img(data[0]).astype('float32')\n",
    "            label  = data[1].astype('float32')\n",
    "            global iter_num\n",
    "            all_iter.append(iter_num)\n",
    "            iter_num += 1\n",
    "\n",
    "            predict = model.forward(img)\n",
    "\n",
    "            loss = F.square_error_cost(predict,label=label)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            all_loss.append(avg_loss.numpy()[0])\n",
    "\n",
    "            # 反向计算\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "            if batch_id % 100 ==0:\n",
    "                print('epoch is {}, batch_id is {} ,loss is {}, '.format(i,batch_id,avg_loss.numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 0, batch_id is 0 ,loss is [26.537415], \n",
      "epoch is 0, batch_id is 100 ,loss is [6.984982], \n",
      "epoch is 0, batch_id is 200 ,loss is [5.7257037], \n",
      "epoch is 0, batch_id is 300 ,loss is [3.4913542], \n",
      "epoch is 0, batch_id is 400 ,loss is [4.8942275], \n",
      "epoch is 0, batch_id is 500 ,loss is [4.67894], \n",
      "epoch is 0, batch_id is 600 ,loss is [4.384933], \n",
      "epoch is 0, batch_id is 700 ,loss is [5.5107174], \n",
      "epoch is 0, batch_id is 800 ,loss is [5.5378904], \n",
      "epoch is 0, batch_id is 900 ,loss is [4.455756], \n",
      "epoch is 0, batch_id is 1000 ,loss is [5.96354], \n",
      "epoch is 0, batch_id is 1100 ,loss is [5.0181923], \n",
      "epoch is 0, batch_id is 1200 ,loss is [3.397202], \n",
      "epoch is 0, batch_id is 1300 ,loss is [6.4146233], \n",
      "epoch is 0, batch_id is 1400 ,loss is [2.8140035], \n",
      "epoch is 0, batch_id is 1500 ,loss is [3.1082387], \n",
      "epoch is 0, batch_id is 1600 ,loss is [3.5628386], \n",
      "epoch is 0, batch_id is 1700 ,loss is [3.7949479], \n",
      "epoch is 0, batch_id is 1800 ,loss is [2.9563012], \n",
      "epoch is 0, batch_id is 1900 ,loss is [2.892633], \n",
      "epoch is 0, batch_id is 2000 ,loss is [5.8793216], \n",
      "epoch is 0, batch_id is 2100 ,loss is [4.8834085], \n",
      "epoch is 0, batch_id is 2200 ,loss is [5.630287], \n",
      "epoch is 0, batch_id is 2300 ,loss is [3.2832818], \n",
      "epoch is 0, batch_id is 2400 ,loss is [2.926161], \n",
      "epoch is 0, batch_id is 2500 ,loss is [2.8375764], \n",
      "epoch is 0, batch_id is 2600 ,loss is [3.5630233], \n",
      "epoch is 0, batch_id is 2700 ,loss is [3.250645], \n",
      "epoch is 0, batch_id is 2800 ,loss is [5.219345], \n",
      "epoch is 0, batch_id is 2900 ,loss is [2.738081], \n",
      "epoch is 0, batch_id is 3000 ,loss is [4.0585136], \n",
      "epoch is 0, batch_id is 3100 ,loss is [3.8537877], \n",
      "epoch is 0, batch_id is 3200 ,loss is [2.9350643], \n",
      "epoch is 0, batch_id is 3300 ,loss is [2.353844], \n",
      "epoch is 0, batch_id is 3400 ,loss is [2.6270852], \n",
      "epoch is 0, batch_id is 3500 ,loss is [2.3050961], \n",
      "epoch is 0, batch_id is 3600 ,loss is [3.5106606], \n",
      "epoch is 0, batch_id is 3700 ,loss is [1.5121953], \n",
      "epoch is 1, batch_id is 0 ,loss is [3.731565], \n",
      "epoch is 1, batch_id is 100 ,loss is [3.5880694], \n",
      "epoch is 1, batch_id is 200 ,loss is [3.6040554], \n",
      "epoch is 1, batch_id is 300 ,loss is [5.261092], \n",
      "epoch is 1, batch_id is 400 ,loss is [3.048171], \n",
      "epoch is 1, batch_id is 500 ,loss is [1.6571769], \n",
      "epoch is 1, batch_id is 600 ,loss is [5.65794], \n",
      "epoch is 1, batch_id is 700 ,loss is [1.7742263], \n",
      "epoch is 1, batch_id is 800 ,loss is [4.690388], \n",
      "epoch is 1, batch_id is 900 ,loss is [4.1407857], \n",
      "epoch is 1, batch_id is 1000 ,loss is [2.359252], \n",
      "epoch is 1, batch_id is 1100 ,loss is [4.507365], \n",
      "epoch is 1, batch_id is 1200 ,loss is [4.1912513], \n",
      "epoch is 1, batch_id is 1300 ,loss is [3.8482878], \n",
      "epoch is 1, batch_id is 1400 ,loss is [3.1643252], \n",
      "epoch is 1, batch_id is 1500 ,loss is [2.6970296], \n",
      "epoch is 1, batch_id is 1600 ,loss is [1.5796528], \n",
      "epoch is 1, batch_id is 1700 ,loss is [3.1650825], \n",
      "epoch is 1, batch_id is 1800 ,loss is [1.0999379], \n",
      "epoch is 1, batch_id is 1900 ,loss is [3.9266877], \n",
      "epoch is 1, batch_id is 2000 ,loss is [4.9399652], \n",
      "epoch is 1, batch_id is 2100 ,loss is [3.4248776], \n",
      "epoch is 1, batch_id is 2200 ,loss is [1.882585], \n",
      "epoch is 1, batch_id is 2300 ,loss is [2.9699483], \n",
      "epoch is 1, batch_id is 2400 ,loss is [3.8414462], \n",
      "epoch is 1, batch_id is 2500 ,loss is [4.5919743], \n",
      "epoch is 1, batch_id is 2600 ,loss is [3.3570862], \n",
      "epoch is 1, batch_id is 2700 ,loss is [3.705191], \n",
      "epoch is 1, batch_id is 2800 ,loss is [3.3412976], \n",
      "epoch is 1, batch_id is 2900 ,loss is [3.7220504], \n",
      "epoch is 1, batch_id is 3000 ,loss is [5.6183906], \n",
      "epoch is 1, batch_id is 3100 ,loss is [4.2054353], \n",
      "epoch is 1, batch_id is 3200 ,loss is [1.5233154], \n",
      "epoch is 1, batch_id is 3300 ,loss is [3.9339843], \n",
      "epoch is 1, batch_id is 3400 ,loss is [4.613002], \n",
      "epoch is 1, batch_id is 3500 ,loss is [1.5404855], \n",
      "epoch is 1, batch_id is 3600 ,loss is [3.5709248], \n",
      "epoch is 1, batch_id is 3700 ,loss is [5.8030834], \n",
      "epoch is 2, batch_id is 0 ,loss is [2.082138], \n",
      "epoch is 2, batch_id is 100 ,loss is [5.72276], \n",
      "epoch is 2, batch_id is 200 ,loss is [2.221511], \n",
      "epoch is 2, batch_id is 300 ,loss is [1.768929], \n",
      "epoch is 2, batch_id is 400 ,loss is [2.4625852], \n",
      "epoch is 2, batch_id is 500 ,loss is [3.61936], \n",
      "epoch is 2, batch_id is 600 ,loss is [2.5637412], \n",
      "epoch is 2, batch_id is 700 ,loss is [5.048194], \n",
      "epoch is 2, batch_id is 800 ,loss is [3.324332], \n",
      "epoch is 2, batch_id is 900 ,loss is [3.36099], \n",
      "epoch is 2, batch_id is 1000 ,loss is [2.115676], \n",
      "epoch is 2, batch_id is 1100 ,loss is [5.796451], \n",
      "epoch is 2, batch_id is 1200 ,loss is [5.098098], \n",
      "epoch is 2, batch_id is 1300 ,loss is [5.6742687], \n",
      "epoch is 2, batch_id is 1400 ,loss is [4.9399643], \n",
      "epoch is 2, batch_id is 1500 ,loss is [4.270769], \n",
      "epoch is 2, batch_id is 1600 ,loss is [4.0700965], \n",
      "epoch is 2, batch_id is 1700 ,loss is [3.601319], \n",
      "epoch is 2, batch_id is 1800 ,loss is [2.156683], \n",
      "epoch is 2, batch_id is 1900 ,loss is [2.5166736], \n",
      "epoch is 2, batch_id is 2000 ,loss is [2.1342642], \n",
      "epoch is 2, batch_id is 2100 ,loss is [2.3056822], \n",
      "epoch is 2, batch_id is 2200 ,loss is [3.7593794], \n",
      "epoch is 2, batch_id is 2300 ,loss is [2.5130076], \n",
      "epoch is 2, batch_id is 2400 ,loss is [4.48489], \n",
      "epoch is 2, batch_id is 2500 ,loss is [3.9804668], \n",
      "epoch is 2, batch_id is 2600 ,loss is [2.2515714], \n",
      "epoch is 2, batch_id is 2700 ,loss is [2.057023], \n",
      "epoch is 2, batch_id is 2800 ,loss is [2.287293], \n",
      "epoch is 2, batch_id is 2900 ,loss is [7.732767], \n",
      "epoch is 2, batch_id is 3000 ,loss is [1.6675305], \n",
      "epoch is 2, batch_id is 3100 ,loss is [6.0398693], \n",
      "epoch is 2, batch_id is 3200 ,loss is [1.9298995], \n",
      "epoch is 2, batch_id is 3300 ,loss is [3.4504027], \n",
      "epoch is 2, batch_id is 3400 ,loss is [4.503867], \n",
      "epoch is 2, batch_id is 3500 ,loss is [3.3719273], \n",
      "epoch is 2, batch_id is 3600 ,loss is [4.654932], \n",
      "epoch is 2, batch_id is 3700 ,loss is [3.0756538], \n",
      "epoch is 3, batch_id is 0 ,loss is [3.6521034], \n",
      "epoch is 3, batch_id is 100 ,loss is [5.861274], \n",
      "epoch is 3, batch_id is 200 ,loss is [8.513412], \n",
      "epoch is 3, batch_id is 300 ,loss is [2.5116882], \n",
      "epoch is 3, batch_id is 400 ,loss is [2.3812003], \n",
      "epoch is 3, batch_id is 500 ,loss is [3.5204735], \n",
      "epoch is 3, batch_id is 600 ,loss is [4.316677], \n",
      "epoch is 3, batch_id is 700 ,loss is [5.742832], \n",
      "epoch is 3, batch_id is 800 ,loss is [3.8118215], \n",
      "epoch is 3, batch_id is 900 ,loss is [4.0523663], \n",
      "epoch is 3, batch_id is 1000 ,loss is [4.927253], \n",
      "epoch is 3, batch_id is 1100 ,loss is [3.8878832], \n",
      "epoch is 3, batch_id is 1200 ,loss is [6.193057], \n",
      "epoch is 3, batch_id is 1300 ,loss is [1.9469376], \n",
      "epoch is 3, batch_id is 1400 ,loss is [2.5367157], \n",
      "epoch is 3, batch_id is 1500 ,loss is [1.7194222], \n",
      "epoch is 3, batch_id is 1600 ,loss is [3.962415], \n",
      "epoch is 3, batch_id is 1700 ,loss is [2.8727922], \n",
      "epoch is 3, batch_id is 1800 ,loss is [3.0115614], \n",
      "epoch is 3, batch_id is 1900 ,loss is [2.8574421], \n",
      "epoch is 3, batch_id is 2000 ,loss is [3.2553184], \n",
      "epoch is 3, batch_id is 2100 ,loss is [2.6928725], \n",
      "epoch is 3, batch_id is 2200 ,loss is [4.211127], \n",
      "epoch is 3, batch_id is 2300 ,loss is [2.6416767], \n",
      "epoch is 3, batch_id is 2400 ,loss is [2.4496393], \n",
      "epoch is 3, batch_id is 2500 ,loss is [2.3764472], \n",
      "epoch is 3, batch_id is 2600 ,loss is [6.7825027], \n",
      "epoch is 3, batch_id is 2700 ,loss is [2.2465127], \n",
      "epoch is 3, batch_id is 2800 ,loss is [2.447264], \n",
      "epoch is 3, batch_id is 2900 ,loss is [3.1131172], \n",
      "epoch is 3, batch_id is 3000 ,loss is [1.6017753], \n",
      "epoch is 3, batch_id is 3100 ,loss is [4.765335], \n",
      "epoch is 3, batch_id is 3200 ,loss is [6.225534], \n",
      "epoch is 3, batch_id is 3300 ,loss is [3.7568665], \n",
      "epoch is 3, batch_id is 3400 ,loss is [2.1691656], \n",
      "epoch is 3, batch_id is 3500 ,loss is [2.9495554], \n",
      "epoch is 3, batch_id is 3600 ,loss is [4.0025306], \n",
      "epoch is 3, batch_id is 3700 ,loss is [2.0408583], \n",
      "epoch is 4, batch_id is 0 ,loss is [2.3322074], \n",
      "epoch is 4, batch_id is 100 ,loss is [2.1394913], \n",
      "epoch is 4, batch_id is 200 ,loss is [1.6521133], \n",
      "epoch is 4, batch_id is 300 ,loss is [3.699305], \n",
      "epoch is 4, batch_id is 400 ,loss is [2.9704423], \n",
      "epoch is 4, batch_id is 500 ,loss is [2.4400036], \n",
      "epoch is 4, batch_id is 600 ,loss is [1.6085842], \n",
      "epoch is 4, batch_id is 700 ,loss is [4.179664], \n",
      "epoch is 4, batch_id is 800 ,loss is [4.1011004], \n",
      "epoch is 4, batch_id is 900 ,loss is [2.2873735], \n",
      "epoch is 4, batch_id is 1000 ,loss is [2.7210999], \n",
      "epoch is 4, batch_id is 1100 ,loss is [5.3735313], \n",
      "epoch is 4, batch_id is 1200 ,loss is [2.6636636], \n",
      "epoch is 4, batch_id is 1300 ,loss is [1.8807693], \n",
      "epoch is 4, batch_id is 1400 ,loss is [3.0255876], \n",
      "epoch is 4, batch_id is 1500 ,loss is [5.042387], \n",
      "epoch is 4, batch_id is 1600 ,loss is [2.9891005], \n",
      "epoch is 4, batch_id is 1700 ,loss is [2.817202], \n",
      "epoch is 4, batch_id is 1800 ,loss is [4.482291], \n",
      "epoch is 4, batch_id is 1900 ,loss is [2.7528389], \n",
      "epoch is 4, batch_id is 2000 ,loss is [5.2743597], \n",
      "epoch is 4, batch_id is 2100 ,loss is [2.3434665], \n",
      "epoch is 4, batch_id is 2200 ,loss is [1.2660455], \n",
      "epoch is 4, batch_id is 2300 ,loss is [2.4597719], \n",
      "epoch is 4, batch_id is 2400 ,loss is [2.9292128], \n",
      "epoch is 4, batch_id is 2500 ,loss is [7.7635674], \n",
      "epoch is 4, batch_id is 2600 ,loss is [4.5580034], \n",
      "epoch is 4, batch_id is 2700 ,loss is [5.027151], \n",
      "epoch is 4, batch_id is 2800 ,loss is [3.6436071], \n",
      "epoch is 4, batch_id is 2900 ,loss is [3.568018], \n",
      "epoch is 4, batch_id is 3000 ,loss is [2.2992969], \n",
      "epoch is 4, batch_id is 3100 ,loss is [0.9722894], \n",
      "epoch is 4, batch_id is 3200 ,loss is [2.5717824], \n",
      "epoch is 4, batch_id is 3300 ,loss is [3.3657274], \n",
      "epoch is 4, batch_id is 3400 ,loss is [3.713109], \n",
      "epoch is 4, batch_id is 3500 ,loss is [1.7426927], \n",
      "epoch is 4, batch_id is 3600 ,loss is [3.5160162], \n",
      "epoch is 4, batch_id is 3700 ,loss is [1.656096], \n",
      "epoch is 5, batch_id is 0 ,loss is [5.61282], \n",
      "epoch is 5, batch_id is 100 ,loss is [3.2321749], \n",
      "epoch is 5, batch_id is 200 ,loss is [1.94397], \n",
      "epoch is 5, batch_id is 300 ,loss is [2.917604], \n",
      "epoch is 5, batch_id is 400 ,loss is [5.923554], \n",
      "epoch is 5, batch_id is 500 ,loss is [4.376197], \n",
      "epoch is 5, batch_id is 600 ,loss is [2.5500755], \n",
      "epoch is 5, batch_id is 700 ,loss is [2.2298975], \n",
      "epoch is 5, batch_id is 800 ,loss is [3.6494563], \n",
      "epoch is 5, batch_id is 900 ,loss is [5.180133], \n",
      "epoch is 5, batch_id is 1000 ,loss is [3.2010183], \n",
      "epoch is 5, batch_id is 1100 ,loss is [2.5171347], \n",
      "epoch is 5, batch_id is 1200 ,loss is [2.1998236], \n",
      "epoch is 5, batch_id is 1300 ,loss is [2.3630157], \n",
      "epoch is 5, batch_id is 1400 ,loss is [0.680993], \n",
      "epoch is 5, batch_id is 1500 ,loss is [2.0416613], \n",
      "epoch is 5, batch_id is 1600 ,loss is [0.7326416], \n",
      "epoch is 5, batch_id is 1700 ,loss is [5.185123], \n",
      "epoch is 5, batch_id is 1800 ,loss is [3.3050535], \n",
      "epoch is 5, batch_id is 1900 ,loss is [3.8928213], \n",
      "epoch is 5, batch_id is 2000 ,loss is [3.6338725], \n",
      "epoch is 5, batch_id is 2100 ,loss is [3.9253259], \n",
      "epoch is 5, batch_id is 2200 ,loss is [4.2462544], \n",
      "epoch is 5, batch_id is 2300 ,loss is [2.896565], \n",
      "epoch is 5, batch_id is 2400 ,loss is [4.194168], \n",
      "epoch is 5, batch_id is 2500 ,loss is [3.693987], \n",
      "epoch is 5, batch_id is 2600 ,loss is [4.5067115], \n",
      "epoch is 5, batch_id is 2700 ,loss is [4.4394045], \n",
      "epoch is 5, batch_id is 2800 ,loss is [3.1615999], \n",
      "epoch is 5, batch_id is 2900 ,loss is [3.2028248], \n",
      "epoch is 5, batch_id is 3000 ,loss is [2.6607342], \n",
      "epoch is 5, batch_id is 3100 ,loss is [2.8979945], \n",
      "epoch is 5, batch_id is 3200 ,loss is [2.2368178], \n",
      "epoch is 5, batch_id is 3300 ,loss is [3.0909722], \n",
      "epoch is 5, batch_id is 3400 ,loss is [3.2598956], \n",
      "epoch is 5, batch_id is 3500 ,loss is [3.1931796], \n",
      "epoch is 5, batch_id is 3600 ,loss is [1.8223358], \n",
      "epoch is 5, batch_id is 3700 ,loss is [3.3711712], \n",
      "epoch is 6, batch_id is 0 ,loss is [3.04519], \n",
      "epoch is 6, batch_id is 100 ,loss is [2.3709364], \n",
      "epoch is 6, batch_id is 200 ,loss is [5.4618444], \n",
      "epoch is 6, batch_id is 300 ,loss is [2.2812877], \n",
      "epoch is 6, batch_id is 400 ,loss is [2.1517577], \n",
      "epoch is 6, batch_id is 500 ,loss is [3.8587403], \n",
      "epoch is 6, batch_id is 600 ,loss is [5.039449], \n",
      "epoch is 6, batch_id is 700 ,loss is [1.3753195], \n",
      "epoch is 6, batch_id is 800 ,loss is [2.4255104], \n",
      "epoch is 6, batch_id is 900 ,loss is [3.6659198], \n",
      "epoch is 6, batch_id is 1000 ,loss is [1.7992439], \n",
      "epoch is 6, batch_id is 1100 ,loss is [4.8303347], \n",
      "epoch is 6, batch_id is 1200 ,loss is [4.0054903], \n",
      "epoch is 6, batch_id is 1300 ,loss is [3.0130146], \n",
      "epoch is 6, batch_id is 1400 ,loss is [4.771919], \n",
      "epoch is 6, batch_id is 1500 ,loss is [4.8693705], \n",
      "epoch is 6, batch_id is 1600 ,loss is [2.4589987], \n",
      "epoch is 6, batch_id is 1700 ,loss is [3.2704244], \n",
      "epoch is 6, batch_id is 1800 ,loss is [4.931757], \n",
      "epoch is 6, batch_id is 1900 ,loss is [1.992146], \n",
      "epoch is 6, batch_id is 2000 ,loss is [6.5890484], \n",
      "epoch is 6, batch_id is 2100 ,loss is [2.741325], \n",
      "epoch is 6, batch_id is 2200 ,loss is [2.0982518], \n",
      "epoch is 6, batch_id is 2300 ,loss is [2.8842149], \n",
      "epoch is 6, batch_id is 2400 ,loss is [3.979404], \n",
      "epoch is 6, batch_id is 2500 ,loss is [3.0670717], \n",
      "epoch is 6, batch_id is 2600 ,loss is [4.4229918], \n",
      "epoch is 6, batch_id is 2700 ,loss is [2.1650653], \n",
      "epoch is 6, batch_id is 2800 ,loss is [2.8427653], \n",
      "epoch is 6, batch_id is 2900 ,loss is [3.085395], \n",
      "epoch is 6, batch_id is 3000 ,loss is [3.8843074], \n",
      "epoch is 6, batch_id is 3100 ,loss is [4.0450478], \n",
      "epoch is 6, batch_id is 3200 ,loss is [4.2667036], \n",
      "epoch is 6, batch_id is 3300 ,loss is [5.300022], \n",
      "epoch is 6, batch_id is 3400 ,loss is [5.296399], \n",
      "epoch is 6, batch_id is 3500 ,loss is [4.122405], \n",
      "epoch is 6, batch_id is 3600 ,loss is [4.027521], \n",
      "epoch is 6, batch_id is 3700 ,loss is [4.1977224], \n",
      "epoch is 7, batch_id is 0 ,loss is [2.0538242], \n",
      "epoch is 7, batch_id is 100 ,loss is [3.0923846], \n",
      "epoch is 7, batch_id is 200 ,loss is [5.997036], \n",
      "epoch is 7, batch_id is 300 ,loss is [3.733653], \n",
      "epoch is 7, batch_id is 400 ,loss is [2.3677585], \n",
      "epoch is 7, batch_id is 500 ,loss is [3.7825532], \n",
      "epoch is 7, batch_id is 600 ,loss is [3.0400038], \n",
      "epoch is 7, batch_id is 700 ,loss is [4.4763722], \n",
      "epoch is 7, batch_id is 800 ,loss is [2.8508942], \n",
      "epoch is 7, batch_id is 900 ,loss is [2.9311447], \n",
      "epoch is 7, batch_id is 1000 ,loss is [2.4708374], \n",
      "epoch is 7, batch_id is 1100 ,loss is [5.1355243], \n",
      "epoch is 7, batch_id is 1200 ,loss is [3.2301245], \n",
      "epoch is 7, batch_id is 1300 ,loss is [3.9498851], \n",
      "epoch is 7, batch_id is 1400 ,loss is [4.840835], \n",
      "epoch is 7, batch_id is 1500 ,loss is [3.1013951], \n",
      "epoch is 7, batch_id is 1600 ,loss is [2.3941667], \n",
      "epoch is 7, batch_id is 1700 ,loss is [9.006253], \n",
      "epoch is 7, batch_id is 1800 ,loss is [5.146124], \n",
      "epoch is 7, batch_id is 1900 ,loss is [3.4874308], \n",
      "epoch is 7, batch_id is 2000 ,loss is [3.7637062], \n",
      "epoch is 7, batch_id is 2100 ,loss is [3.3676035], \n",
      "epoch is 7, batch_id is 2200 ,loss is [3.286561], \n",
      "epoch is 7, batch_id is 2300 ,loss is [2.4119868], \n",
      "epoch is 7, batch_id is 2400 ,loss is [4.7697353], \n",
      "epoch is 7, batch_id is 2500 ,loss is [3.2362483], \n",
      "epoch is 7, batch_id is 2600 ,loss is [1.7195044], \n",
      "epoch is 7, batch_id is 2700 ,loss is [5.640731], \n",
      "epoch is 7, batch_id is 2800 ,loss is [6.4490285], \n",
      "epoch is 7, batch_id is 2900 ,loss is [3.5109413], \n",
      "epoch is 7, batch_id is 3000 ,loss is [2.1503358], \n",
      "epoch is 7, batch_id is 3100 ,loss is [1.9601904], \n",
      "epoch is 7, batch_id is 3200 ,loss is [3.7845812], \n",
      "epoch is 7, batch_id is 3300 ,loss is [3.1488562], \n",
      "epoch is 7, batch_id is 3400 ,loss is [4.5405827], \n",
      "epoch is 7, batch_id is 3500 ,loss is [1.8835578], \n",
      "epoch is 7, batch_id is 3600 ,loss is [2.2538664], \n",
      "epoch is 7, batch_id is 3700 ,loss is [3.187401], \n",
      "epoch is 8, batch_id is 0 ,loss is [5.8824744], \n",
      "epoch is 8, batch_id is 100 ,loss is [2.2572474], \n",
      "epoch is 8, batch_id is 200 ,loss is [3.4715066], \n",
      "epoch is 8, batch_id is 300 ,loss is [2.823606], \n",
      "epoch is 8, batch_id is 400 ,loss is [1.6888599], \n",
      "epoch is 8, batch_id is 500 ,loss is [1.6405742], \n",
      "epoch is 8, batch_id is 600 ,loss is [2.0083516], \n",
      "epoch is 8, batch_id is 700 ,loss is [2.9723096], \n",
      "epoch is 8, batch_id is 800 ,loss is [1.907327], \n",
      "epoch is 8, batch_id is 900 ,loss is [5.071393], \n",
      "epoch is 8, batch_id is 1000 ,loss is [3.615506], \n",
      "epoch is 8, batch_id is 1100 ,loss is [2.1219492], \n",
      "epoch is 8, batch_id is 1200 ,loss is [4.9843187], \n",
      "epoch is 8, batch_id is 1300 ,loss is [3.154946], \n",
      "epoch is 8, batch_id is 1400 ,loss is [3.410172], \n",
      "epoch is 8, batch_id is 1500 ,loss is [4.450378], \n",
      "epoch is 8, batch_id is 1600 ,loss is [1.8098316], \n",
      "epoch is 8, batch_id is 1700 ,loss is [1.6526346], \n",
      "epoch is 8, batch_id is 1800 ,loss is [2.4419408], \n",
      "epoch is 8, batch_id is 1900 ,loss is [2.6365275], \n",
      "epoch is 8, batch_id is 2000 ,loss is [1.6858662], \n",
      "epoch is 8, batch_id is 2100 ,loss is [2.6183088], \n",
      "epoch is 8, batch_id is 2200 ,loss is [2.446578], \n",
      "epoch is 8, batch_id is 2300 ,loss is [2.036039], \n",
      "epoch is 8, batch_id is 2400 ,loss is [2.0893989], \n",
      "epoch is 8, batch_id is 2500 ,loss is [2.725312], \n",
      "epoch is 8, batch_id is 2600 ,loss is [3.7268944], \n",
      "epoch is 8, batch_id is 2700 ,loss is [2.5389557], \n",
      "epoch is 8, batch_id is 2800 ,loss is [2.381949], \n",
      "epoch is 8, batch_id is 2900 ,loss is [3.1020823], \n",
      "epoch is 8, batch_id is 3000 ,loss is [3.3200607], \n",
      "epoch is 8, batch_id is 3100 ,loss is [3.21979], \n",
      "epoch is 8, batch_id is 3200 ,loss is [6.278081], \n",
      "epoch is 8, batch_id is 3300 ,loss is [4.6759076], \n",
      "epoch is 8, batch_id is 3400 ,loss is [5.0323925], \n",
      "epoch is 8, batch_id is 3500 ,loss is [1.6545613], \n",
      "epoch is 8, batch_id is 3600 ,loss is [2.8247285], \n",
      "epoch is 8, batch_id is 3700 ,loss is [3.4221303], \n",
      "epoch is 9, batch_id is 0 ,loss is [1.5151908], \n",
      "epoch is 9, batch_id is 100 ,loss is [3.6476493], \n",
      "epoch is 9, batch_id is 200 ,loss is [4.615419], \n",
      "epoch is 9, batch_id is 300 ,loss is [3.4976332], \n",
      "epoch is 9, batch_id is 400 ,loss is [5.0315027], \n",
      "epoch is 9, batch_id is 500 ,loss is [6.107003], \n",
      "epoch is 9, batch_id is 600 ,loss is [5.1699505], \n",
      "epoch is 9, batch_id is 700 ,loss is [3.2213864], \n",
      "epoch is 9, batch_id is 800 ,loss is [2.6466577], \n",
      "epoch is 9, batch_id is 900 ,loss is [4.600643], \n",
      "epoch is 9, batch_id is 1000 ,loss is [3.3291273], \n",
      "epoch is 9, batch_id is 1100 ,loss is [2.5114417], \n",
      "epoch is 9, batch_id is 1200 ,loss is [2.7106516], \n",
      "epoch is 9, batch_id is 1300 ,loss is [4.7832155], \n",
      "epoch is 9, batch_id is 1400 ,loss is [3.0988693], \n",
      "epoch is 9, batch_id is 1500 ,loss is [2.5208347], \n",
      "epoch is 9, batch_id is 1600 ,loss is [3.4394999], \n",
      "epoch is 9, batch_id is 1700 ,loss is [1.9772302], \n",
      "epoch is 9, batch_id is 1800 ,loss is [2.1410773], \n",
      "epoch is 9, batch_id is 1900 ,loss is [3.580797], \n",
      "epoch is 9, batch_id is 2000 ,loss is [2.8879578], \n",
      "epoch is 9, batch_id is 2100 ,loss is [4.596205], \n",
      "epoch is 9, batch_id is 2200 ,loss is [2.9628527], \n",
      "epoch is 9, batch_id is 2300 ,loss is [4.1944404], \n",
      "epoch is 9, batch_id is 2400 ,loss is [4.814313], \n",
      "epoch is 9, batch_id is 2500 ,loss is [2.7292287], \n",
      "epoch is 9, batch_id is 2600 ,loss is [4.710209], \n",
      "epoch is 9, batch_id is 2700 ,loss is [3.6662698], \n",
      "epoch is 9, batch_id is 2800 ,loss is [2.0399423], \n",
      "epoch is 9, batch_id is 2900 ,loss is [1.728847], \n",
      "epoch is 9, batch_id is 3000 ,loss is [3.4139683], \n",
      "epoch is 9, batch_id is 3100 ,loss is [2.6614325], \n",
      "epoch is 9, batch_id is 3200 ,loss is [2.7599354], \n",
      "epoch is 9, batch_id is 3300 ,loss is [2.7405238], \n",
      "epoch is 9, batch_id is 3400 ,loss is [2.6492105], \n",
      "epoch is 9, batch_id is 3500 ,loss is [1.5818497], \n",
      "epoch is 9, batch_id is 3600 ,loss is [3.8009534], \n",
      "epoch is 9, batch_id is 3700 ,loss is [3.6065357], \n"
     ]
    }
   ],
   "source": [
    "model = MINIST()\n",
    "train(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1682d540df0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_iter,all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = './models/minist.pdparams'\n",
    "paddle.save(model.state_dict(),model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28 at 0x1683AAED3A0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1682f791940>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im_path = './work/example_0.jpg'\n",
    "im = Image.open(im_path)\n",
    "print(im)\n",
    "plt.imshow(im,cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义转换函数\n",
    "def load_img(img_path):\n",
    "    im = Image.open(img_path)\n",
    "    im = im.resize((28,28),Image.ANTIALIAS)# 转换为 28*28的图片\n",
    "    plt.imshow(im,cmap='binary')\n",
    "    im = np.array(im).reshape(1,-1).astype('float32')\n",
    "\n",
    "    im = 1 - im/255 # 原来的数字部分是白色的，减去以后直接黑变白，白变黑\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MINIST()\n",
    "para_dict = paddle.load(model_file_path)\n",
    "model.load_dict(para_dict)\n",
    "\n",
    "model.eval()#启动预测模式\n",
    "tensor_img = load_img(img_path=im_path)\n",
    "result = model(paddle.to_tensor(tensor_img))\n",
    "print(result.numpy().astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.2247438 -1.2247438 -1.2247438]\n",
      " [ 0.         0.         0.       ]\n",
      " [ 1.2247438  1.2247438  1.2247438]]\n",
      "std 4.0, mean 2.449489742783178, \n",
      " output [-1.22474487  0.          1.22474487]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.nn import BatchNorm1D\n",
    "\n",
    "data = np.array(\n",
    "    [[1,2,3],[4,5,6],[7,8,9]]\n",
    ").astype(np.float32)\n",
    "\n",
    "bn = BatchNorm1D(num_features=3)\n",
    "\n",
    "x = paddle.to_tensor(data)\n",
    "y = bn(x)\n",
    "\n",
    "print(y.numpy())\n",
    "\n",
    "a = np.array([1,4,7])\n",
    "a_mean = a.mean()\n",
    "a_std = a.std()\n",
    "b = (a - a_mean) / a_std\n",
    "print('std {}, mean {}, \\n output {}'.format(a_mean, a_std, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer\n",
    "import paddle \n",
    "from paddle.nn import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入的维度为128，每个有2个mutihead,一共有1层，FFN是2048\n",
    "transformer = Transformer(128, 2, 1, 1, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_input = paddle.rand((1,4,128))\n",
    "de_input = paddle.rand((1,5,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder q , k v [1, 4, 128] [1, 4, 128] [1, 4, 128]\n",
      "decoder ----q , k v [1, 2, 4, 64] [1, 2, 4, 64] [1, 2, 4, 64]\n",
      "product shape  [1, 2, 4, 4]\n",
      "weight shape  [1, 2, 4, 4]\n",
      "out shape :  [1, 2, 4, 64]\n",
      "before linear1 [1, 4, 128]\n",
      "before linear1 [1, 4, 512]\n",
      "the out put of the encod tensor  [1, 4, 128]\n",
      "decoder : target shape is [1, 5, 128], memory shape is [1, 4, 128] \n",
      "decoder q , k v [1, 5, 128] [1, 5, 128] [1, 5, 128]\n",
      "decoder ----q , k v [1, 2, 5, 64] [1, 2, 5, 64] [1, 2, 5, 64]\n",
      "product shape  [1, 2, 5, 5]\n",
      "weight shape  [1, 2, 5, 5]\n",
      "out shape :  [1, 2, 5, 64]\n",
      "decoder q , k v [1, 5, 128] [1, 4, 128] [1, 4, 128]\n",
      "decoder ----q , k v [1, 2, 5, 64] [1, 2, 4, 64] [1, 2, 4, 64]\n",
      "product shape  [1, 2, 5, 4]\n",
      "weight shape  [1, 2, 5, 4]\n",
      "out shape :  [1, 2, 5, 64]\n",
      "[1, 5, 128]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 5, 128], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
       "       [[[-1.49321604, -0.28307801,  0.83334619, -0.87134349,  1.20998108,  0.19434968, -0.64225578, -0.15082240, -0.61264586, -0.80401546, -1.07422817, -2.68932366,  0.27309713, -0.22947390,  0.38533080,  0.27733913,  0.29825753,  0.51675415,  0.00558193,  0.75838894,  0.07894260,  0.27313933,  1.61141980, -0.09224652,  0.01086797, -2.32126665,  1.29084003,  0.44524041, -0.01648587,  1.45857012,  0.69419670, -0.02097510,  0.99541414,  1.18747091,  0.58792722, -0.21235347, -1.22499502, -0.85437024,  0.69836462, -0.34874383,  0.11895289, -0.04558991,  0.62552571,  0.35140732, -0.65421343, -0.08775064,  0.94345421, -1.39003181, -0.32999229, -1.04585648, -1.63545585,  0.31441805,  0.99661869, -0.03393826,  1.57341969, -0.50625330,  0.72578907, -0.22307609, -1.06811464, -1.07336438, -1.95975983,  0.62225449,  0.21939208,  1.67042089, -0.68851727,  1.02309918,  2.11421466, -0.13184252,  0.80020767, -0.80848455, -1.30067563,  1.29344678, -0.36236086,  1.26290512, -0.48792252,  2.34943271,  1.01654160, -0.50659007, -0.12546700,  0.80475736,  0.37695676, -0.69557041,  1.52214539,  0.59335887,  2.34808350, -1.39572728,  0.92135656, -0.57316434, -1.28325725,  0.32909310, -0.09331199,  0.62444955,  1.74181592, -0.28193122, -1.16345906,  0.66116977, -0.33194083,  0.17139617, -1.55055034, -0.55299175, -0.57523859, -0.97546697, -0.42717400, -1.19744778, -0.92807370, -0.17194898,  0.76731604, -1.79517508, -0.46905407, -1.03238964,  0.54490715,  0.36201826, -0.41971308,  1.12385261,  1.16793227, -0.86189950,  0.53256649,  0.71908021,  0.57808632, -0.33652747, -0.88155311, -1.56301212,  0.11654929,  0.18967710, -0.85064489, -2.43778348,  0.56404209,  2.38517141],\n",
       "         [-1.36608887, -0.41143134, -0.35362244, -0.67105788,  1.22516215,  0.14051437, -1.70019889, -0.69608116, -0.25438172, -0.47381938, -0.61017060, -2.35511994,  0.16791321, -0.87583220, -0.60784417,  0.03066297,  0.56890798, -2.07538962,  0.53191727,  0.39515767,  0.70432222, -0.11547805,  2.24999094,  0.88937014, -0.05325855, -2.11604023,  1.60629296,  0.26815969,  0.65088636,  0.74005854,  0.58340245,  0.60288978,  1.05184472,  1.02733254, -0.09096263, -1.09930468, -1.32933044, -1.23635793, -0.76624531,  0.07521030,  0.77952462,  0.75035292,  1.75806820, -0.14807029, -1.41949248, -1.16397917, -0.00710328, -0.65021467,  0.10833491, -1.62886119, -0.75260454,  0.29935774,  1.10992491,  0.42574018,  0.76528811, -0.95869118,  0.69314408,  0.32785338, -0.70440656, -0.19649181, -0.88148212,  0.88540864, -0.54549462,  0.70760345, -1.25491869,  0.58983600,  1.35661900,  0.15907207,  0.23804216, -0.87847805, -0.63172674,  0.39914274, -0.93169010,  2.03081417, -0.53773314,  1.53667557,  0.52217072, -0.35634160, -0.62861508,  0.94336081, -0.41885334, -1.21923554,  2.18342352, -0.76328403,  2.22947311, -1.36902654,  0.09028395, -1.05522668, -0.67380446, -0.21899439, -0.43047169,  1.57989800,  1.33985400, -0.62134290,  0.94216764,  1.11768377, -0.43495396,  0.30503279, -0.20840795, -0.25706479,  0.58401048, -0.49400762,  1.29578769, -1.87419665, -0.70150524,  0.20452820, -0.24186657, -1.77519155, -0.81265861,  0.18781613,  0.49384311,  1.23944056, -1.00036657,  1.88343954,  1.21534467, -0.22536279,  0.31140381,  0.73284674,  0.02783797,  1.23649156, -0.60592997, -1.47278690, -1.00925732, -0.10733854, -0.95102948,  0.11373851,  1.19335139,  2.07254815],\n",
       "         [-1.51270008, -0.22249311,  0.55142200, -0.18846492, -0.36255160,  1.30001962, -0.98091137, -0.66333520, -0.36302933, -0.48900115, -1.62287903, -2.40771532,  0.16432978, -0.36524716, -0.22803646, -0.10850474,  0.85114682, -0.63058883,  0.21862769, -0.53674227,  0.59995115, -0.23694888,  0.35432905,  0.64462507,  0.09291146, -1.30106533,  1.42837882, -0.95553327, -0.10504942,  1.15773761,  0.54112774, -0.38855872,  1.44251561, -0.35455433, -0.78916973, -0.41729268, -0.64942497, -1.25329125,  1.61357594,  0.50144339,  0.49434215,  0.00336481,  1.10082173, -0.36570475, -0.52332503, -1.62728667,  0.02356842, -1.36642456, -0.43622431, -0.85307515, -0.49246320,  0.30251601,  1.04123712, -0.42632532,  2.00653672, -1.02911651,  0.83415163,  0.08366482, -1.00998545, -0.10112537, -2.32608795,  0.02389096,  0.85875577,  0.27987799, -1.45865905, -0.30156499,  1.82806838,  0.53991717, -0.30515471, -1.09790301,  0.03877229,  1.69929814, -0.97702891,  1.59244609, -0.76114315,  2.07203412,  0.80777878, -0.26509351,  0.17227228,  0.65176016, -0.11654411, -0.87043840,  1.65258384, -0.18112659,  2.24920535, -1.67780995,  1.11850786, -0.96714038, -1.74107671,  0.73153204,  0.07564207,  1.53889334,  0.97657347, -0.01917952, -0.54353458,  0.12234333, -0.03354452, -0.52510631, -0.49286687,  0.27653596,  0.14895524,  0.41101715,  2.00228286, -1.85195470, -1.38119876,  0.37237397,  0.33047453, -1.07303512,  0.05386800, -0.83698314,  0.78650904,  0.08535697, -0.60618383,  2.90932250,  0.90655655, -0.50798649,  0.88884240,  0.74518681, -0.34533301,  0.76019520, -0.34948674, -0.58069074, -0.37290409,  0.40967584, -0.77219212, -1.57763147,  0.56491452,  2.24616289],\n",
       "         [-1.00232148, -0.55150563, -0.03227062,  0.34817824, -0.02098246,  0.88633841, -0.93132889, -1.00975871, -0.23704639, -0.23785977, -1.97199321, -1.66360629, -0.31282592, -0.34953591, -0.97378474,  0.26734465,  0.25952888,  1.13827324, -0.87113595, -0.75176227, -0.11812651,  0.25849512,  1.03565848, -0.47749943, -0.53684759, -1.52669048,  1.03097367, -0.61565500, -0.33909661,  0.99670917,  0.41466862,  0.41399384,  0.89637226,  0.48167557, -0.33255649, -0.65074444, -0.33720976, -0.61295199,  1.09458733,  1.01004398,  0.80541319,  0.17087267,  1.19768286,  0.35686973, -0.40972495, -0.49609828,  1.01315451, -2.17229462,  0.47462696, -0.39518052, -1.17691278,  1.65550613,  0.87341630, -0.30687717,  1.67705476, -0.36549389, -0.13915202,  0.88229585, -0.81045496, -0.84952176, -1.00898123,  0.52877808,  0.74580503,  1.30560255, -2.16042233,  0.10195417,  2.12872982, -0.12857139, -0.28939956, -0.69496304, -0.22260371,  0.28443435, -1.19289422,  2.23948884, -0.81159449,  1.34448957,  0.81266612, -0.19987634,  0.02220891, -0.15221445,  0.24803646, -0.49131212,  0.68614024,  0.25652322,  1.67123222, -0.88254064,  1.33609092, -1.41723382, -2.03255224, -0.08085610,  0.29705814,  1.73933971,  0.84566224, -0.66688120, -0.21735993,  0.52028161, -0.33948338,  0.38558105, -1.14072001,  0.05903718,  0.27784950,  0.55725747,  2.59830284, -2.49141359, -1.28298187,  0.20632643,  1.05930448, -1.40518618, -0.08507862, -0.68565744,  0.62362975,  0.17252102, -1.28941560,  1.70199585,  1.10498297,  0.28100300,  0.68106002,  0.94743943, -0.15688357,  0.50877535, -0.91961002, -1.89411128,  0.05192034,  0.47421551, -0.29277226, -2.25839090, -0.22486395,  2.25817418],\n",
       "         [-1.37345243, -0.49574175, -0.32212061, -0.73439664,  1.50490153,  0.86546445, -0.91464019, -0.33483332, -0.08127932,  0.15034431, -1.11234379, -2.00178695, -0.45582134, -0.00677940, -0.59496874, -0.15324540, -0.26367292, -0.10383005, -0.18417352,  0.05034138, -0.35766387,  0.13158691,  1.00858164,  0.14791694, -0.25505850, -2.27434087,  1.73108900, -0.52223164,  0.58074498,  0.33839995, -0.13631058, -0.31657806,  2.00966740,  0.93559182, -0.07760996, -1.39489746,  0.05966324, -0.17551129,  0.84173447,  0.43097901,  1.22306371,  0.03094738,  2.11215496, -0.06967594, -1.16877019, -0.72065943,  0.13716118, -2.55855584,  0.06298523, -0.63273555, -0.65831268,  0.85489976,  1.41545010,  0.42121956,  1.30810106,  0.28861961,  0.85369951, -0.62582231, -0.88172811, -0.35801122, -2.04745746,  1.41499925,  0.96961111,  0.70828688, -2.12681770,  0.61218137,  0.81550676, -0.18648174,  0.60994804, -0.34126601,  0.36737767,  0.86309606, -1.25313950,  1.87241638, -0.31516233,  1.48463881,  0.93893558, -0.96702260, -0.06647854,  0.47517702,  0.16958126, -1.46904850,  2.23803067, -0.86475974,  1.67827678, -1.31500602,  0.26952979, -0.85678875, -1.83172464,  0.87921262,  0.26179460,  1.50688994,  0.93255448, -0.83491427,  0.24176718,  0.94543308,  0.16423954,  0.91161925, -2.03386855,  0.08560402, -0.86493653,  0.12624146,  0.59129453, -2.00150681, -1.01613939,  0.01714978,  0.40521309, -1.57498002, -0.40918198, -0.56031185,  0.73862547,  0.20139158, -1.17122114,  2.17286348,  1.15916634,  0.32544646,  0.89057714,  0.61248690, -0.07569371, -0.09139550, -0.15607165, -1.57445061, -0.95313752, -0.14243270, -0.70592844,  0.38300124,  0.76413178,  0.82527626]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(en_input,de_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTest(paddle.nn.Layer)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73fe03891eabd6446a090ee4c22d8dcac73542d36d6aee5d53443fd4b857a5ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
